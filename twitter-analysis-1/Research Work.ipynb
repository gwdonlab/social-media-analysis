{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing libraries\n",
    "\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure',figsize=(17,13))\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "#from wordcloud import WordCloud,STOPWORDS, ImageColorGenerator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"Library Setup Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4f2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6904f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing twitter credentials for scrapping the data\n",
    "\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_key = \"\"\n",
    "access_secret = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636eaaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(consumer_key, consumer_secret) \n",
    "auth.set_access_token(access_key, access_secret) \n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d51f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tweets = 1500\n",
    "tweets = []\n",
    "likes = []\n",
    "time = []\n",
    "\n",
    "for i in tw.Cursor(api.search_tweets, q = \"#Moderna -filter:retweets\", lang = 'en', tweet_mode = \"extended\").items(number_of_tweets):\n",
    "    tweets.append(i.full_text)\n",
    "    likes.append(i.favorite_count)\n",
    "    time.append(i.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dbbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc265d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting text to dataframe\n",
    "\n",
    "dataframe = pd.DataFrame({'tweets' : tweets, 'likes' : likes, 'time' : time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining statistics\n",
    "\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = px.histogram(dataframe, x='time', template='plotly_white', title='Number of tweets about moderna per day')\n",
    "figure.update_xaxes(categoryorder='category descending', title='Date').update_yaxes(title='Number of tweets about moderna per day')\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for unfilled values\n",
    "\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec42747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Re-tweets\n",
    "\n",
    "no_rt_df = dataframe[~dataframe.tweets.str.contains(\"RT\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a017a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf84f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting Index\n",
    "\n",
    "new_df = no_rt_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea909571",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce501b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining Most liked tweets\n",
    "\n",
    "most_liked_tweets = new_df.loc[dataframe.likes.nlargest(10).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_liked_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298572ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the text\n",
    "\n",
    "def cleanUpTweet(text):\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "    # Remove retweets:\n",
    "    text = re.sub(r'RT : ', '', text)\n",
    "    # Remove urls\n",
    "    text = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', text) \n",
    "    #removes stop words\n",
    "    text = re.sub(r'the', '', text)\n",
    "    text = re.sub(r'and', '', text)\n",
    "    text = re.sub(r'to', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    return text\n",
    "\n",
    "new_df['tweets'] = new_df['tweets'].apply(cleanUpTweet)\n",
    "#new_df[\"tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword Removal\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\", \".join(stopwords.words('english'))\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "\n",
    "new_df['tweets'] = new_df['tweets'].apply(remove_stopwords)\n",
    "new_df[\"tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Emoji\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "new_df[\"tweets\"] = new_df[\"tweets\"].apply(str)\n",
    "new_df[\"tweets\"] = new_df[\"tweets\"].apply(remove_emoji)\n",
    "new_df[\"tweets\"]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abe644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting most occured words\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "cnt = Counter()\n",
    "\n",
    "for text in new_df[\"tweets\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into tokens\n",
    "\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "new_df['tokenized'] = new_df['tweets'].apply(tokenization)\n",
    "new_df['tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "new_df['lemmatized'] = new_df['tokenized'].apply(lambda x: lemmatizer(x))\n",
    "new_df.head()\n",
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_words=[]\n",
    "for i in range(len(new_df['lemmatized'])):\n",
    "    a=new_df['lemmatized'][i]\n",
    "    for i in a:\n",
    "        all_words.append(i)\n",
    "all_words=pd.Series(np.array(all_words))\n",
    "\n",
    "common_words=all_words.value_counts()[:50].rename_axis('Common Words').reset_index(name='count')\n",
    "\n",
    "fig = px.treemap(common_words, path=['Common Words'], values='count',title='50 Most Common Words In Tweets')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop([\"time\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop([\"likes\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11092c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop([\"tokenized\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c209fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop([\"tweets\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cd90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"lemmatized\"] = new_df[\"lemmatized\"].apply(str)\n",
    "new_df[\"lemmatized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b471f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e37019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c9a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a function that determines subjectivity and polarity from the textblob package\n",
    "\n",
    "def getTextSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "def getTextPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5026621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply these functions to the dataframe\n",
    "\n",
    "new_df['Subjectivity'] = new_df['lemmatized'].apply(getTextSubjectivity)\n",
    "new_df['Polarity'] = new_df['lemmatized'].apply(getTextPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds a function to calculate and categorize each tweet as Negative, Neutral, and Positive\n",
    "\n",
    "def getTextAnalysis(a):\n",
    "    if a < 0:\n",
    "        return \"Negative\"\n",
    "    elif a == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0efe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates another column called Score and applies the function to the dataframe\n",
    "\n",
    "new_df['Score'] = new_df['Polarity'].apply(getTextAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates percentage of positive, negative, and neutral tweets of 1000 tweets\n",
    "\n",
    "positive = new_df[new_df['Score'] == 'Positive']\n",
    "print(str(positive.shape[0]/(new_df.shape[0])*100) + \" % of positive tweets\")\n",
    "positive = new_df[new_df['Score'] == 'Neutral']\n",
    "print(str(positive.shape[0]/(new_df.shape[0])*100) + \" % of neutral tweets\")\n",
    "positive = new_df[new_df['Score'] == 'Negative']\n",
    "print(str(positive.shape[0]/(new_df.shape[0])*100) + \" % of negative tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentages of sentiment for 500 tweets\n",
    "\n",
    "#41.85110663983904 % of positive tweets\n",
    "#41.85110663983904 % of neutral tweets\n",
    "#16.297786720321934 % of negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0fe443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
